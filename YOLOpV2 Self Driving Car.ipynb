{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11824696,"sourceType":"datasetVersion","datasetId":7426757}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# YOLOPv2","metadata":{}},{"cell_type":"markdown","source":"You Only Look Once for Panopitic Driving Perception.","metadata":{}},{"cell_type":"markdown","source":"# Downloading the Source","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/hustvl/YOLOP.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:34:29.090895Z","iopub.execute_input":"2025-05-15T17:34:29.091475Z","iopub.status.idle":"2025-05-15T17:34:35.878343Z","shell.execute_reply.started":"2025-05-15T17:34:29.091439Z","shell.execute_reply":"2025-05-15T17:34:35.877430Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'YOLOP'...\nremote: Enumerating objects: 431, done.\u001b[K\nremote: Counting objects: 100% (426/426), done.\u001b[K\nremote: Compressing objects: 100% (233/233), done.\u001b[K\nremote: Total 431 (delta 212), reused 335 (delta 184), pack-reused 5 (from 1)\u001b[K\nReceiving objects: 100% (431/431), 140.17 MiB | 38.98 MiB/s, done.\nResolving deltas: 100% (212/212), done.\nUpdating files: 100% (95/95), done.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%cd YOLOP\n!ls\n!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:34:41.209309Z","iopub.execute_input":"2025-05-15T17:34:41.209592Z","iopub.status.idle":"2025-05-15T17:34:44.366854Z","shell.execute_reply.started":"2025-05-15T17:34:41.209564Z","shell.execute_reply":"2025-05-15T17:34:44.366141Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"/kaggle/working/YOLOP/YOLOP\n export_onnx.py   lib\t    'README _CH.md'     test.jpg       tools\n hubconf.py\t  LICENSE    README.md\t        test_onnx.py   weights\n inference\t  pictures   requirements.txt   toolkits\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.67.1)\nRequirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.1.8)\nRequirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (3.0.12)\nRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.7.2)\nRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.26.4)\nRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.11.0.86)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (11.1.0)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (6.0.2)\nRequirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2.6.2.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.12.2)\nRequirement already satisfied: prefetch_generator in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.0.3)\nRequirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (2.37.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (1.2.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->-r requirements.txt (line 6)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->-r requirements.txt (line 6)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->-r requirements.txt (line 6)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->-r requirements.txt (line 6)) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->-r requirements.txt (line 6)) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->-r requirements.txt (line 6)) (2.4.1)\nRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 11)) (3.20.3)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from seaborn->-r requirements.txt (line 12)) (2.2.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 15)) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 15)) (3.6.0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn->-r requirements.txt (line 12)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn->-r requirements.txt (line 12)) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->-r requirements.txt (line 6)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->-r requirements.txt (line 6)) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.5->-r requirements.txt (line 6)) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.5->-r requirements.txt (line 6)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.5->-r requirements.txt (line 6)) (2024.2.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:34:51.081257Z","iopub.execute_input":"2025-05-15T17:34:51.081551Z","iopub.status.idle":"2025-05-15T17:34:51.199458Z","shell.execute_reply.started":"2025-05-15T17:34:51.081523Z","shell.execute_reply":"2025-05-15T17:34:51.198588Z"}},"outputs":[{"name":"stdout","text":" export_onnx.py   lib\t    'README _CH.md'     test.jpg       tools\n hubconf.py\t  LICENSE    README.md\t        test_onnx.py   weights\n inference\t  pictures   requirements.txt   toolkits\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 0 -> cuda (empty is cpu)\n!python3 tools/demo.py --device 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:34:54.394681Z","iopub.execute_input":"2025-05-15T17:34:54.395241Z","iopub.status.idle":"2025-05-15T17:36:00.659842Z","shell.execute_reply.started":"2025-05-15T17:34:54.395208Z","shell.execute_reply":"2025-05-15T17:36:00.659151Z"}},"outputs":[{"name":"stdout","text":"['/kaggle/working/YOLOP/YOLOP/tools', '/kaggle/lib/kagglegym', '/kaggle/lib', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/kaggle/working/YOLOP/YOLOP']\n=> creating runs/BddDataset/_2025-05-15-17-35\nUsing torch 2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MB)\n\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n video 1/1 (1/267) /kaggle/working/YOLOP/YOLOP/inference/videos/1.mp4: /usr/local/lib/python3.11/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n2it [00:01,  2.13it/s]                                                          \n3it [00:01,  2.89it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n4it [00:01,  3.48it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n5it [00:01,  4.00it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n6it [00:01,  4.34it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n7it [00:01,  4.67it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n8it [00:02,  4.88it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n9it [00:02,  5.06it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n10it [00:02,  5.19it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n11it [00:02,  5.26it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n12it [00:02,  5.38it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n13it [00:03,  5.47it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n14it [00:03,  5.55it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n15it [00:03,  5.58it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n16it [00:03,  5.58it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n17it [00:03,  5.43it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n18it [00:04,  5.21it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n19it [00:04,  5.26it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n20it [00:04,  5.27it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n21it [00:04,  5.32it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n22it [00:04,  5.27it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n23it [00:04,  5.30it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n24it [00:05,  5.32it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n25it [00:05,  5.34it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n26it [00:05,  5.29it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n27it [00:05,  5.30it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n28it [00:05,  5.25it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n29it [00:06,  5.30it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n30it [00:06,  5.28it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n31it [00:06,  5.33it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n32it [00:06,  5.28it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n33it [00:06,  5.28it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n34it [00:07,  5.33it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n35it [00:07,  5.35it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n36it [00:07,  5.35it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n37it [00:07,  5.33it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n38it [00:07,  5.26it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n39it [00:07,  5.29it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n40it [00:08,  5.27it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n41it [00:08,  5.31it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n42it [00:08,  5.31it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n43it [00:08,  5.31it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n44it [00:08,  5.16it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n45it [00:09,  5.22it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n46it [00:09,  5.25it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n47it [00:09,  5.27it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n48it [00:09,  5.29it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n49it [00:09,  5.26it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n50it [00:10,  5.18it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n51it [00:10,  5.06it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n52it [00:10,  5.15it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n53it [00:10,  5.21it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n54it [00:10,  5.18it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n55it [00:11,  5.22it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n56it [00:11,  5.23it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n57it [00:11,  5.28it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n58it [00:11,  5.27it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n59it [00:11,  5.33it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n60it [00:11,  5.28it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n61it [00:12,  5.20it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n62it [00:12,  5.19it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n63it [00:12,  5.13it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n64it [00:12,  5.14it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n65it [00:12,  5.19it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n66it [00:13,  5.24it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n67it [00:13,  5.22it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n68it [00:13,  5.26it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n69it [00:13,  5.28it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n70it [00:13,  5.24it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n71it [00:14,  5.30it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n72it [00:14,  5.27it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n73it [00:14,  5.29it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n74it [00:14,  5.25it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n75it [00:14,  5.13it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n76it [00:15,  5.09it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n77it [00:15,  5.08it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n78it [00:15,  5.09it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n79it [00:15,  5.21it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n80it [00:15,  5.05it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n81it [00:16,  5.01it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n82it [00:16,  5.01it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n83it [00:16,  5.10it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n84it [00:16,  5.05it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n85it [00:16,  5.09it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n86it [00:17,  5.04it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n87it [00:17,  5.10it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n88it [00:17,  5.04it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n89it [00:17,  5.16it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n90it [00:17,  5.09it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n91it [00:18,  5.17it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n92it [00:18,  5.24it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n93it [00:18,  5.21it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n94it [00:18,  5.19it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n95it [00:18,  5.19it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n96it [00:18,  5.26it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n97it [00:19,  5.29it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n98it [00:19,  5.30it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n99it [00:19,  5.34it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n100it [00:19,  5.36it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n101it [00:19,  5.37it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n102it [00:20,  5.32it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n103it [00:20,  5.19it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n104it [00:20,  5.23it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n105it [00:20,  5.29it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n106it [00:20,  5.30it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n107it [00:21,  5.31it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n108it [00:21,  5.25it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n109it [00:21,  5.35it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n110it [00:21,  5.39it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n111it [00:21,  5.40it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n112it [00:21,  5.37it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n113it [00:22,  5.30it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n114it [00:22,  5.27it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n115it [00:22,  5.31it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n116it [00:22,  5.32it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n117it [00:22,  5.28it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n118it [00:23,  5.31it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n119it [00:23,  5.32it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n120it [00:23,  5.35it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n121it [00:23,  5.39it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n122it [00:23,  5.37it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n123it [00:24,  5.38it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n124it [00:24,  5.34it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n125it [00:24,  5.35it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n126it [00:24,  5.34it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n127it [00:24,  5.38it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n128it [00:24,  5.37it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n129it [00:25,  5.37it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n130it [00:25,  5.40it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n131it [00:25,  5.40it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n132it [00:25,  5.33it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n133it [00:25,  5.35it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n134it [00:26,  5.37it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n135it [00:26,  5.38it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n136it [00:26,  5.33it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n137it [00:26,  5.34it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n138it [00:26,  5.28it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n139it [00:27,  5.26it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n140it [00:27,  5.18it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n141it [00:27,  5.23it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n142it [00:27,  5.20it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n143it [00:27,  5.18it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n144it [00:28,  5.10it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n145it [00:28,  5.19it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n146it [00:28,  5.15it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n147it [00:28,  5.17it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n148it [00:28,  5.14it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n149it [00:28,  5.13it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n150it [00:29,  5.16it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n151it [00:29,  5.07it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n152it [00:29,  5.04it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n153it [00:29,  5.12it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n154it [00:29,  5.03it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n155it [00:30,  4.76it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n156it [00:30,  4.76it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n157it [00:30,  4.92it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n158it [00:30,  4.88it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n159it [00:31,  4.94it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n160it [00:31,  4.93it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n161it [00:31,  5.02it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n162it [00:31,  5.06it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n163it [00:31,  4.97it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n164it [00:32,  4.69it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n165it [00:32,  4.72it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n166it [00:32,  4.69it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n167it [00:32,  4.84it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n168it [00:32,  4.86it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n169it [00:33,  4.80it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n170it [00:33,  4.81it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n171it [00:33,  4.88it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n172it [00:33,  4.90it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n173it [00:33,  5.00it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n174it [00:34,  5.00it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n175it [00:34,  4.97it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n176it [00:34,  4.97it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n177it [00:34,  4.85it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n178it [00:34,  4.90it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n179it [00:35,  5.05it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n180it [00:35,  5.04it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n181it [00:35,  5.03it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n182it [00:35,  5.10it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n183it [00:35,  5.09it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n184it [00:36,  5.16it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n185it [00:36,  5.14it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n186it [00:36,  5.18it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n187it [00:36,  5.18it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n188it [00:36,  5.09it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n189it [00:37,  5.13it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n190it [00:37,  5.12it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n191it [00:37,  5.11it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n192it [00:37,  5.13it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n193it [00:37,  5.11it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n194it [00:38,  5.11it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n195it [00:38,  5.07it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n196it [00:38,  5.07it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n197it [00:38,  5.06it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n198it [00:38,  5.05it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n199it [00:38,  5.07it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n200it [00:39,  5.12it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n201it [00:39,  5.17it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n202it [00:39,  5.24it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n203it [00:39,  5.18it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n204it [00:39,  5.12it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n205it [00:40,  4.90it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n206it [00:40,  4.92it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n207it [00:40,  5.06it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n208it [00:40,  5.01it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n209it [00:40,  5.07it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n210it [00:41,  5.06it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n211it [00:41,  5.07it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n212it [00:41,  5.04it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n213it [00:41,  5.08it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n214it [00:41,  5.12it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n215it [00:42,  5.10it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n216it [00:42,  5.04it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n217it [00:42,  4.98it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n218it [00:42,  4.98it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n219it [00:42,  5.07it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n220it [00:43,  5.14it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n221it [00:43,  5.18it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n222it [00:43,  5.21it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n223it [00:43,  5.15it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n224it [00:43,  5.11it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n225it [00:44,  5.14it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n226it [00:44,  5.12it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n227it [00:44,  5.20it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n228it [00:44,  5.22it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n229it [00:44,  5.27it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n230it [00:45,  5.25it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n231it [00:45,  5.23it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n232it [00:45,  5.28it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n233it [00:45,  5.29it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n234it [00:45,  5.20it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n235it [00:46,  5.16it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n236it [00:46,  5.28it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n237it [00:46,  5.22it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n238it [00:46,  5.24it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n239it [00:46,  5.23it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n240it [00:46,  5.23it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n241it [00:47,  5.31it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n242it [00:47,  5.24it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n243it [00:47,  5.18it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n244it [00:47,  5.18it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n245it [00:47,  5.22it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n246it [00:48,  5.23it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n247it [00:48,  5.32it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n248it [00:48,  5.37it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n249it [00:48,  5.36it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n250it [00:48,  5.29it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n251it [00:49,  5.31it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n252it [00:49,  5.26it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n253it [00:49,  5.25it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n254it [00:49,  5.23it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n255it [00:49,  5.28it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n256it [00:50,  5.25it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n257it [00:50,  5.09it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n258it [00:50,  5.20it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n259it [00:50,  5.22it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n260it [00:50,  5.23it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n261it [00:50,  5.24it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n262it [00:51,  5.27it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n263it [00:51,  5.29it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n264it [00:51,  5.30it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n265it [00:51,  5.34it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n266it [00:51,  5.33it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \n267it [00:52,  5.13it/s]ggle/working/YOLOP/YOLOP/inference/videos/1.mp4: \nResults saved to inference/output\nDone. (53.034s)\ninf : (0.0223s/frame)   nms : (0.0024s/frame)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from IPython.display import Video, display\n\ndisplay(Video('/kaggle/working/YOLOP/inference/output/1.mp4', embed=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:36:05.030727Z","iopub.execute_input":"2025-05-15T17:36:05.031020Z","iopub.status.idle":"2025-05-15T17:36:05.038410Z","shell.execute_reply.started":"2025-05-15T17:36:05.030990Z","shell.execute_reply":"2025-05-15T17:36:05.037651Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Video object>","text/html":"<video controls  >\n <source src=\"data:None;base64,/kaggle/working/YOLOP/inference/output/1.mp4\" type=\"None\">\n Your browser does not support the video tag.\n </video>"},"metadata":{}}],"execution_count":8}]}